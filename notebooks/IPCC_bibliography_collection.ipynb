{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bibtexparser\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bib_file(path):\n",
    "    with open(path, 'r', encoding='utf-8') as fichier:\n",
    "        contenu_bib = fichier.read()\n",
    "    parser = bibtexparser.bparser.BibTexParser(common_strings=True)\n",
    "    bib_database = bibtexparser.loads(contenu_bib, parser=parser)\n",
    "    return bib_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgi=[]\n",
    "dataframes_i={}\n",
    "for i in ['01','02','03','04','05','06','07','08','09','10','11','12']:\n",
    "    df=pd.DataFrame(read_bib_file(f\"../IPCC_bibliography/AR6/WG1/IPCC_AR6_WGI_References_Chapter{i}.bib\").entries)\n",
    "    df['wg']='wg1'\n",
    "    df['chap']=f\"wg1_chap_{i}\"\n",
    "    wgi.append(len(df.doi.dropna())/len(df))\n",
    "    df_name = f'df_i_{i}' \n",
    "    dataframes_i[df_name] = df\n",
    "print(wgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgiii=[]\n",
    "dataframes_iii={}\n",
    "for i in ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17']:\n",
    "    print(i)\n",
    "    df=pd.DataFrame(read_bib_file(f\"../IPCC_bibliography/AR6/WG3/IPCC_AR6_WGIII_References_Chapter{i}.bib\").entries)\n",
    "    df['wg']='wg3'\n",
    "    df['chap']=f\"wg3_chap_{i}\"\n",
    "    wgiii.append(len(df.doi.dropna())/len(df))\n",
    "    df_name = f'df_iii_{i}' \n",
    "    dataframes_iii[df_name] = df\n",
    "print(wgiii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get doi from glutton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doi(row):\n",
    "    title=row.title\n",
    "    author=str(row.author).split(',')[0]\n",
    "    url=f\"https://cloud.science-miner.com/glutton/service/lookup?atitle={title}&firstAuthor={author}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return data.get('DOI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgii=[]\n",
    "wgii_update=[]\n",
    "dataframes_ii = {}\n",
    "for i in ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18']:\n",
    "    df=pd.DataFrame(read_bib_file(f\"../IPCC_bibliography/AR6/WG2/IPCC_AR6_WGII_References_Chapter{i}.bib\").entries)\n",
    "    wgii.append(len(df.doi.dropna())/len(df))\n",
    "    df.loc[pd.isna(df.doi),'doi']=df.loc[pd.isna(df.doi),:].progress_apply(get_doi, axis=1)\n",
    "    wgii_update.append(len(df.doi.dropna())/len(df))\n",
    "    df['wg']='wg2'\n",
    "    df['chap']=f\"wg2_chap_{i}\"\n",
    "    df_name = f'df_ii{i}' \n",
    "    dataframes_ii[df_name] = df\n",
    "print(wgii)\n",
    "print(wgii_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgii_cross=[]\n",
    "wgii_cross_update=[]\n",
    "dataframes_cross_ii = {}\n",
    "\n",
    "for i in range(1,8):\n",
    "    df=pd.DataFrame(read_bib_file(f\"../IPCC_bibliography/AR6/WG2_CROSS/IPCC_AR6_WGII_References_CCP{i}.bib\").entries)\n",
    "    wgii_cross.append(len(df.doi.dropna())/len(df))\n",
    "    df.loc[pd.isna(df.doi),'doi']=df.loc[pd.isna(df.doi),:].progress_apply(get_doi, axis=1)\n",
    "    wgii_cross_update.append(len(df.doi.dropna())/len(df))\n",
    "    df['wg']='wg2_cross'\n",
    "    df['chap']=f\"wg2_cross_chap_{i}\"\n",
    "    df_name = f'df_cross_ii_{i}' \n",
    "    dataframes_cross_ii[df_name] = df\n",
    "print(wgii_cross)\n",
    "print(wgii_cross_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../IPCC_bibliography/AR6/structured_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for each wg\n",
    "df_wgi = pd.concat(list(dataframes_i.values()), ignore_index=True)\n",
    "df_wgii = pd.concat(list(dataframes_ii.values()), ignore_index=True)\n",
    "df_cross_wgii = pd.concat(list(dataframes_cross_ii.values()), ignore_index=True)\n",
    "df_wgiii = pd.concat(list(dataframes_iii.values()), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wgi.to_json(path+'data_wg1.jsonl', orient='records', lines=True)\n",
    "df_wgii.to_json(path+'data_wg2.jsonl', orient='records', lines=True)\n",
    "df_cross_wgii.to_json(path+'data_cross_wg2.jsonl', orient='records', lines=True)\n",
    "df_wgiii.to_json(path+'data_wg3.jsonl', orient='records', lines=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
