% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Mapping scientific communities at scale},
  pdfkeywords={scanR, VOSviewer, scientific ccommunity, research
portal, Elasticsearch, network analysis},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[left=3cm, right=3cm, top=3cm, bottom=3cm]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
% for compatibility with pandoc 2.10
\newenvironment{cslreferences}%
  {\setlength{\parindent}{0pt}%
  \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces}%
  {\par}

\title{Mapping scientific communities at scale}
\usepackage{authblk}
\author[%
  1%
  ]{%
  Victor Barbier%
  %
  %
}
\author[%
  1%
  ]{%
  Eric Jeangirard%
  %
  %
}
\affil[1]{French Ministry of Higher Education and Research, Paris,
France}
\date{January 2025}

\makeatletter
\def\@maketitle{%
  \newpage \null \vskip 2em
  \begin {center}%
    \let \footnote \thanks
         {\LARGE \@title \par}%
         \vskip 1.5em%
                {\large \lineskip .5em%
                  \begin {tabular}[t]{c}%
                    \@author
                  \end {tabular}\par}%
                                                \vskip 1em{\large \@date}%
  \end {center}%
  \par
  \vskip 1.5em}
\makeatother

\begin{document}
\maketitle

\textbf{Keywords}: open access, open science, open data, open source

\hypertarget{motivation}{%
\section{1. Motivation}\label{motivation}}

Analysing and mapping scientific communities provides an insight into
the structure and evolution of academic disciplines. This involves
providing an analytical and visual representation of the relationships
between entities (e.g.~researchers, research laboratories, research
themes), with the aim, in particular, of understanding the networks and
dynamics of scientific collaboration, and identifying collaborative
groups and their influences. From the point of view of decision-makers,
this type of tool is useful for strategic decision-making with a view to
public policy and funding.

These maps are generally deduced from data in bibliographic databases
(open or proprietary), based on co-publication or citation information.
In the case of co-publications, two entities (authors, for example) will
be linked if they have collaborated (co-published) on a piece of
research. These links are then symmetrical. In the case of citation
links, two authors will be linked if one cites the research work of
another, in the list of references. This is a directed link, as one
author may cite another without this being reciprocal. A lot of recent
work uses this second approach, for example by trying to calculate
composite indicators of novelty (or innovation) based on citation links.

The quality and completeness of the bibliographic metadata used are, of
course, essential if we are to produce a relevant map. Today, the
quality of open citation data still needs to be improved, cf (Alperin et
al. 2024). On the other hand, it is possible to obtain quality metadata
on publications (and therefore links to co-publications). For example,
the French Open Science Monitor (BSO) has compiled a corpus of French
publications with good coverage cf (Chaignon and Egret 2022). This
corpus is exposed in the French research portal scanR (Jeangirard 2024).
This is a corpus containing about 4 millions publications in all
disciplines. These publications have been enriched with disambuation
persistent identifier (PID) on authors, affiliations and topics. For
authors and affiliations, French-specific PID have been used (idref for
authors and RNSR for laboratories) because they have the best coverage,
even if not perfect. For topics, wikidata identifiers has been used cf
(Foppiano and Romary 2020). Other enrichments, like software detection
are also present, and thus usable as entities to map.

\hypertarget{previous-limits-of-the-scanr-application}{%
\subsection{1.1 Previous limits of the scanR
application}\label{previous-limits-of-the-scanr-application}}

Launched in 2016, the scanR portal used to be a search engine. Its scope
first focused on research entities (institutions, laboratories and
private companies) and was extended in 2020 to cover fundings,
publications, patents and authors. Two main use cases were covered.
Firstly, the ability to generate a list of search results corresponding
to a user query. A list of laboratories, authors, funding or
publications could be generated. Secondly, for each institution (or
laboratory), a unified view of all the data concerning it was grouped
together on a dedicated page in scanR (administrative information, list
of publications, list of funding, main partners, etc.).

However, these functions only gave a flat view of the different
dimensions, without providing any insights into the interactions between
laboratories or authors. For a user interested in a research theme, for
example, the list of the main contributors (those who have co-authored
the most publications) does not give a clear idea of which research
communities are at work and how they interact with each other. A network
analysis tool to describe these interactions and attempt to detect
research communities could therefore enable us to go further in creating
tools to help explore fields of research and innovation.

\hypertarget{network-analysis-limits}{%
\subsection{1.2 Network analysis limits}\label{network-analysis-limits}}

Network analysis tools for bibliographic studies are used to study the
relationships between entities in a corpus. In general, the size of this
corpus is limited because the calculations to determine the nodes, links
and their positions for very large networks require too many resources,
in addition to being very difficult to interpret. As a result, tools
such as VOSViewer offer options for limiting the size of networks. The
first option is to filter publications with too many authors. This is
particularly true of publications in particle physics, which can list
several thousand authors. As well as generating very large networks,
this hyperauthorship can also be seen as reducing the relevance of the
information conveyed by the co-authorship links. The second option
offered by VOSViewer is to set thresholds to limit the number of nodes
directly (minimum number of publications or minimum number of citations
for a node). However, this approach of retaining only the largest nodes
in the network can be an obstacle to scaling up to very large corpora of
several million documents. Indeed, if we wish to concentrate on a few
hundred nodes, the threshold will be very high and the resulting network
risks being just a constellation of single nodes with no links between
them, the other nodes with which they are linked being in fact made
insignificant by the threshold set in terms of the number of
publications (or citations) per node. In addition, the processing time
for a very large corpus of publications can be very long, making such a
tool unusable in a web application where the user expects rapid
interaction with the application.

\hypertarget{network-analysis-at-scale}{%
\section{2. Network analysis at scale}\label{network-analysis-at-scale}}

We propose a method for overcoming the limitations set out above. We
also use a filtering technique to reduce the size of the network, but
with a dual approach: instead of filtering the nodes, we filter the
links.

\hypertarget{focusing-on-strongest-interactions}{%
\subsection{2.1 Focusing on strongest
interactions}\label{focusing-on-strongest-interactions}}

One of the added values of mapping with a network view is to show the
interactions between entities, i.e.~the links between the nodes in the
graph. These links provide crucial information that can be used to
structure communities. If the size of the network needs to be reduced
(for reasons of computation, speed, legibility and interpretability), it
is vital to preserve the links that carry the most information, i.e.~the
strongest interactions. With this reasoning, it seems logical to reduce
the size of the network by only affecting the strongest links.

Thus, from a given corpus, however large, we seek to extract the pairs
of entities with the strongest interactions, for example the most
co-signatures per pair of authors. From this list of pairs, we can
naturally find the nodes of the graph and deduce a new graph. If the
graph has several independent components, i.e.~several unconnected
sub-graphs, we can decide to keep only the main component(s).

\hypertarget{elasticsearch-implementation}{%
\subsection{2.2 Elasticsearch
implementation}\label{elasticsearch-implementation}}

To identify the strongest links, it would be too costly to go through
the entire corpus. We have pre-calculated the links at the level of each
publication. So, if a publication is linked to 3 themes, T1, T2 and T3,
a pre-calculated field, at publication level, contains all T1-T2, T1-T3
and T2-T3 pairs. This co\_topics field represents the co-appearance
links within the publication. We then use elasticsearch's aggregation
functionality to list the most present links, very efficiently.

In practice, a PID is also stored (the wikidata for topics, for example)
to disambiguate entities. In practice, for a given query, elasticsearch
returns a response containing the strongest links, for example:

\begin{Shaded}
\begin{Highlighting}[]
                \FunctionTok{\{}
                    \DataTypeTok{"key"}\FunctionTok{:} \StringTok{"Q15305550\#\#\#carbon sequestration{-}{-}{-}Q7942\#\#\#climate change"}\FunctionTok{,}
                    \DataTypeTok{"doc\_count"}\FunctionTok{:} \DecValTok{17}\FunctionTok{,}
                \FunctionTok{\}}\ErrorTok{,}
                \FunctionTok{\{}
                    \DataTypeTok{"key"}\FunctionTok{:} \StringTok{"Q15305550\#\#\#carbon sequestration{-}{-}{-}Q623\#\#\#carbon"}\FunctionTok{,}
                    \DataTypeTok{"doc\_count"}\FunctionTok{:} \DecValTok{14}\FunctionTok{,}
                \FunctionTok{\}}\ErrorTok{,}
                \FunctionTok{\{}
                    \DataTypeTok{"key"}\FunctionTok{:} \StringTok{"Q15305550\#\#\#Carbon sequestration{-}{-}{-}Q7942\#\#\#Climate change"}\FunctionTok{,}
                    \DataTypeTok{"doc\_count"}\FunctionTok{:} \DecValTok{13}\FunctionTok{,}
                \FunctionTok{\}}\ErrorTok{,}
                \FunctionTok{\{}
                    \DataTypeTok{"key"}\FunctionTok{:} \StringTok{"Q15305550\#\#\#Carbon sequestration{-}{-}{-}Q898653\#\#\#Climate change mitigation"}\FunctionTok{,}
                    \DataTypeTok{"doc\_count"}\FunctionTok{:} \DecValTok{10}\FunctionTok{,}
                \FunctionTok{\}}\ErrorTok{,}
                \FunctionTok{\{}
                    \DataTypeTok{"key"}\FunctionTok{:} \StringTok{"Q397350\#\#\#agroforestry{-}{-}{-}Q8486\#\#\#coffee"}\FunctionTok{,}
                    \DataTypeTok{"doc\_count"}\FunctionTok{:} \DecValTok{10}\FunctionTok{,}
                \FunctionTok{\}}\ErrorTok{,}
                \FunctionTok{\{}
                    \DataTypeTok{"key"}\FunctionTok{:} \StringTok{"Q15305550\#\#\#Carbon sequestration{-}{-}{-}Q1997\#\#\#CO2"}\FunctionTok{,}
                    \DataTypeTok{"doc\_count"}\FunctionTok{:} \DecValTok{9}\FunctionTok{,}
                \FunctionTok{\}}\ErrorTok{,}
                \FunctionTok{\{}
                    \DataTypeTok{"key"}\FunctionTok{:} \StringTok{"Q623\#\#\#carbon{-}{-}{-}Q627\#\#\#nitrogen"}\FunctionTok{,}
                    \DataTypeTok{"doc\_count"}\FunctionTok{:} \DecValTok{9}\FunctionTok{,}
                \FunctionTok{\}}\ErrorTok{,}
                \FunctionTok{\{}
                    \DataTypeTok{"key"}\FunctionTok{:} \StringTok{"Q15305550\#\#\#Carbon sequestration{-}{-}{-}Q623\#\#\#carbon"}\FunctionTok{,}
                    \DataTypeTok{"doc\_count"}\FunctionTok{:} \DecValTok{7}\FunctionTok{,}
                \FunctionTok{\}}\ErrorTok{,}
\end{Highlighting}
\end{Shaded}

\hypertarget{vosviewer-implementation}{%
\subsection{2.3 VOSviewer
implementation}\label{vosviewer-implementation}}

We use the open source VOSviewer online tool for network visualization
\url{https://github.com/neesjanvaneck/VOSviewer-Online}. It is based on
the VOSviewer tool which is very popular for network analysis in
bibliometric studies (Waltman, Eck, and Noyons 2010).

\hypertarget{llm-trick}{%
\subsection{2.4 LLM trick}\label{llm-trick}}

\hypertarget{making-insightful-maps}{%
\section{3. Making insightful maps}\label{making-insightful-maps}}

\hypertarget{citation-hot-topics}{%
\subsection{3.1 Citation / hot topics}\label{citation-hot-topics}}

We use citations data from OpenAlex, which is as of today one of the
best open source datasource. However, citations metadata from OpenAlex
remains incomplete and must therefore be interpreted with caution
(Alperin et al. 2024).

\hypertarget{custom-perimeter}{%
\subsection{3.2 Custom perimeter}\label{custom-perimeter}}

scanR offers this mapping tool for the entire indexed corpus, but it is
also possible to adapt the tool to a restricted perimeter, at the user's
discretion. For example, an institution or laboratory can define its own
corpus (based on a list of publications) and a mapping tool dedicated to
this perimeter is automatically created. Technically, elasticsearch
queries are the same, with just an additional filter to query only the
publications within the perimeter. The tool can be embedded in any
website using an iframe. It's the same principle as the local barometer.
This approach eliminates the need for automatic alignment of
affiliations, which remains a highly complex task. Automation is
possible to a certain extent (L'Hôte and Jeangirard 2021), but human
curation remains necessary in the majority of cases (Jeangirard, Bracco,
and L'Hôte 2024). In this way, users retain control over the definition
of their perimeter, and can, if they wish, have several distinct
perimeters.

\hypertarget{code-availibility}{%
\section{4. Code availibility}\label{code-availibility}}

The code developed for the scanR web application is open source and
available online on GitHub \url{https://github.com/dataesr/scanr-ui}

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{cslreferences}
\leavevmode\hypertarget{ref-alperin2024analysissuitabilityopenalexbibliometric}{}%
Alperin, Juan Pablo, Jason Portenoy, Kyle Demes, Vincent Larivière, and
Stefanie Haustein. 2024. ``An Analysis of the Suitability of Openalex
for Bibliometric Analyses.'' \url{https://arxiv.org/abs/2404.17663}.

\leavevmode\hypertarget{ref-10.1162ux2fqss_a_00179}{}%
Chaignon, Lauranne, and Daniel Egret. 2022. ``Identifying Scientific
Publications Countrywide and Measuring Their Open Access: The Case of
the French Open Science Barometer (Bso).'' \emph{Quantitative Science
Studies} 3 (1): 18--36. \url{https://doi.org/10.1162/qss_a_00179}.

\leavevmode\hypertarget{ref-foppiano2020entity}{}%
Foppiano, Luca, and Laurent Romary. 2020. ``Entity-Fishing: A Dariah
Entity Recognition and Disambiguation Service.'' \emph{Journal of the
Japanese Association for Digital Humanities} 5 (1): 22--60.

\leavevmode\hypertarget{ref-jeangirard:hal-04813230}{}%
Jeangirard, Eric. 2024. ``scanR - Explore public data on French research
and innovation.'' In \emph{euroCRIS SMM 2024}. Paris, France: euroCRIS.
\url{https://hal.science/hal-04813230}.

\leavevmode\hypertarget{ref-jeangirard:hal-04598201}{}%
Jeangirard, Eric, Laetitia Bracco, and Anne L'Hôte. 2024. ``Works-magnet
: aucune de perdue, 10 000 de retrouvées.'' Abes; Journées Abes 2024.
\url{https://doi.org/10.5281/zenodo.11471247}.

\leavevmode\hypertarget{ref-lhote_using_2021}{}%
L'Hôte, Anne, and Eric Jeangirard. 2021. ``Using Elasticsearch for
Entity Recognition in Affiliation Disambiguation.''
\emph{arXiv:2110.01958 {[}Cs{]}}, October.
\url{http://arxiv.org/abs/2110.01958}.

\leavevmode\hypertarget{ref-DBLP:journalsux2fcorrux2fabs-1006-1032}{}%
Waltman, Ludo, Nees Jan van Eck, and Ed C. M. Noyons. 2010. ``A Unified
Approach to Mapping and Clustering of Bibliometric Networks.''
\emph{CoRR} abs/1006.1032. \url{http://arxiv.org/abs/1006.1032}.
\end{cslreferences}


\end{document}
